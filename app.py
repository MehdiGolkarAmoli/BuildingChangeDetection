# Import non-streamlit packages first
import os
os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'
import numpy as np
import matplotlib.pyplot as plt
from shapely.geometry import Polygon, mapping, box
import rasterio
from rasterio.mask import mask
from rasterio.warp import calculate_default_transform, reproject, Resampling
from rasterio.merge import merge
from patchify import patchify, unpatchify
import datetime
import torch
import torchvision
import math
from scipy import ndimage
import ee
import tempfile
import zipfile
from pathlib import Path
import requests
import time
import io
import warnings
import sys
import base64
import json
from importlib import import_module
import geopandas as gpd
import subprocess

# Suppress warnings
warnings.filterwarnings("ignore", category=UserWarning)
warnings.filterwarnings("ignore", category=FutureWarning)
warnings.filterwarnings("ignore", message="Examining the path of torch.classes")

# Now import streamlit as the first streamlit-related import
import streamlit as st

# Set page configuration - MUST BE THE FIRST STREAMLIT COMMAND
st.set_page_config(
    layout="wide", 
    page_title="ÿ≥€åÿ≥ÿ™ŸÖ ÿ™ÿ¥ÿÆ€åÿµ ÿ™ÿ∫€å€åÿ±ÿßÿ™ ÿ≥ÿßÿÆÿ™ŸÖÿßŸÜ€å",
    page_icon="üèóÔ∏è"
)

# Custom CSS for Persian styling with B Nazanin font and improved color theme
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Vazirmatn:wght@300;400;500;600;700&display=swap');
    
    /* Global styling */
    * {
        font-family: 'B Nazanin', 'Vazirmatn', 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif !important;
        direction: rtl !important;
        text-align: right !important;
    }
    
    /* Main background */
    .stApp {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    }
    
    /* Content area */
    .main .block-container {
        background: rgba(255, 255, 255, 0.95);
        border-radius: 20px;
        padding: 2rem;
        box-shadow: 0 8px 32px rgba(0, 0, 0, 0.1);
        backdrop-filter: blur(10px);
    }
    
    /* Headers */
    h1, h2, h3 {
        color: #2c3e50 !important;
        font-weight: 700 !important;
        text-align: center !important;
    }
    
    h1 {
        font-size: 2.5rem !important;
        margin-bottom: 2rem !important;
        text-shadow: 2px 2px 4px rgba(0,0,0,0.1);
    }
    
    h2 {
        font-size: 1.8rem !important;
        color: #34495e !important;
        border-bottom: 3px solid #3498db;
        padding-bottom: 0.5rem;
        margin: 1.5rem 0 !important;
    }
    
    h3 {
        font-size: 1.4rem !important;
        color: #5a6c7d !important;
    }
    
    /* Tabs styling */
    .stTabs [data-baseweb="tab-list"] {
        gap: 8px;
        background: linear-gradient(90deg, #e3f2fd 0%, #bbdefb 100%);
        padding: 10px;
        border-radius: 15px;
    }
    
    .stTabs [data-baseweb="tab"] {
        height: 60px;
        background: white;
        border-radius: 10px;
        padding: 10px 25px;
        font-size: 1.1rem;
        font-weight: 600;
        color: #2c3e50;
        border: 2px solid transparent;
        transition: all 0.3s ease;
    }
    
    .stTabs [data-baseweb="tab"]:hover {
        background: #e8f4f8;
        border-color: #3498db;
        transform: translateY(-2px);
        box-shadow: 0 4px 12px rgba(52, 152, 219, 0.3);
    }
    
    .stTabs [aria-selected="true"] {
        background: linear-gradient(135deg, #3498db 0%, #2980b9 100%) !important;
        color: white !important;
        border-color: #2980b9 !important;
        box-shadow: 0 4px 15px rgba(52, 152, 219, 0.4);
    }
    
    /* Buttons */
    .stButton > button {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border: none;
        border-radius: 12px;
        padding: 12px 30px;
        font-size: 1.1rem;
        font-weight: 600;
        transition: all 0.3s ease;
        box-shadow: 0 4px 15px rgba(102, 126, 234, 0.4);
        width: 100%;
    }
    
    .stButton > button:hover {
        transform: translateY(-3px);
        box-shadow: 0 6px 20px rgba(102, 126, 234, 0.6);
        background: linear-gradient(135deg, #764ba2 0%, #667eea 100%);
    }
    
    /* Info boxes */
    .stAlert {
        border-radius: 12px;
        border-left: 5px solid;
        padding: 1rem;
        margin: 1rem 0;
        backdrop-filter: blur(10px);
    }
    
    [data-baseweb="notification"] {
        border-radius: 12px !important;
        background: rgba(255, 255, 255, 0.9) !important;
    }
    
    /* Success messages */
    .stSuccess {
        background: linear-gradient(135deg, #d4edda 0%, #c3e6cb 100%) !important;
        border-color: #28a745 !important;
        color: #155724 !important;
    }
    
    /* Warning messages */
    .stWarning {
        background: linear-gradient(135deg, #fff3cd 0%, #ffeeba 100%) !important;
        border-color: #ffc107 !important;
        color: #856404 !important;
    }
    
    /* Error messages */
    .stError {
        background: linear-gradient(135deg, #f8d7da 0%, #f5c6cb 100%) !important;
        border-color: #dc3545 !important;
        color: #721c24 !important;
    }
    
    /* Info messages */
    .stInfo {
        background: linear-gradient(135deg, #d1ecf1 0%, #bee5eb 100%) !important;
        border-color: #17a2b8 !important;
        color: #0c5460 !important;
    }
    
    /* Selectbox and inputs */
    .stSelectbox, .stTextInput, .stSlider {
        border-radius: 10px;
    }
    
    [data-baseweb="select"] {
        border-radius: 10px;
        border: 2px solid #e0e0e0;
        transition: all 0.3s ease;
    }
    
    [data-baseweb="select"]:hover {
        border-color: #3498db;
        box-shadow: 0 2px 8px rgba(52, 152, 219, 0.2);
    }
    
    /* Cards */
    .time-selection-card {
        background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
        border-radius: 15px;
        padding: 1.5rem;
        margin-bottom: 1.5rem;
        box-shadow: 0 4px 15px rgba(0, 0, 0, 0.08);
        border: 1px solid #dee2e6;
    }
    
    .time-selection-header {
        font-size: 1.3rem;
        font-weight: 700;
        margin-bottom: 1rem;
        color: #495057;
        border-bottom: 2px solid #6c757d;
        padding-bottom: 0.5rem;
    }
    
    /* Sidebar */
    [data-testid="stSidebar"] {
        background: linear-gradient(180deg, #2c3e50 0%, #34495e 100%);
    }
    
    [data-testid="stSidebar"] * {
        color: white !important;
    }
    
    /* Progress bar */
    .stProgress > div > div {
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        border-radius: 10px;
    }
    
    /* Expander */
    .streamlit-expanderHeader {
        background: linear-gradient(135deg, #e8f4f8 0%, #d4e9f2 100%);
        border-radius: 10px;
        font-weight: 600;
        color: #2c3e50;
        border: 1px solid #b8d4e0;
    }
    
    /* Download button */
    .stDownloadButton > button {
        background: linear-gradient(135deg, #28a745 0%, #218838 100%);
        color: white;
        border: none;
        border-radius: 12px;
        padding: 12px 30px;
        font-weight: 600;
        transition: all 0.3s ease;
    }
    
    .stDownloadButton > button:hover {
        transform: translateY(-3px);
        box-shadow: 0 6px 20px rgba(40, 167, 69, 0.4);
    }
    
    /* File uploader */
    [data-testid="stFileUploader"] {
        background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
        border-radius: 15px;
        padding: 1.5rem;
        border: 2px dashed #6c757d;
    }
    
    /* Columns spacing */
    [data-testid="column"] {
        padding: 0 0.5rem;
    }
    
    /* Matplotlib figures */
    .stImage {
        border-radius: 15px;
        overflow: hidden;
        box-shadow: 0 4px 15px rgba(0, 0, 0, 0.1);
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

# Now import other streamlit-related packages
import folium
from streamlit_folium import folium_static, st_folium
import geemap
import segmentation_models_pytorch as smp
from tqdm import tqdm

# Function to download model from Google Drive with fixed URL and better error handling
@st.cache_data
def download_model_from_gdrive(gdrive_url, local_filename):
    """
    Download a file from Google Drive using the sharing URL with improved error handling
    """
    try:
        correct_file_id = "1m6EScw-mpBIvWV78h4pyjWq1OLQtn2ov"
        
        st.info(f"ÿØÿ± ÿ≠ÿßŸÑ ÿØÿßŸÜŸÑŸàÿØ ŸÖÿØŸÑ ÿßÿ≤ Google Drive (ÿ¥ŸÜÿßÿ≥Ÿá ŸÅÿß€åŸÑ: {correct_file_id})...")
        
        try:
            import gdown
        except ImportError:
            st.info("ÿØÿ± ÿ≠ÿßŸÑ ŸÜÿµÿ® ⁄©ÿ™ÿßÿ®ÿÆÿßŸÜŸá gdown...")
            subprocess.check_call([sys.executable, "-m", "pip", "install", "gdown"])
            import gdown
        
        download_methods = [
            f"https://drive.google.com/uc?id={correct_file_id}",
            f"https://drive.google.com/file/d/{correct_file_id}/view",
            correct_file_id
        ]
        
        for i, method in enumerate(download_methods):
            try:
                st.info(f"ÿ±Ÿàÿ¥ ÿØÿßŸÜŸÑŸàÿØ {i+1} ÿßÿ≤ 3 ÿØÿ± ÿ≠ÿßŸÑ ÿßÿ¨ÿ±ÿß...")
                
                gdown.download(method, local_filename, quiet=False, fuzzy=True)
                
                if os.path.exists(local_filename) and os.path.getsize(local_filename) > 1024:
                    file_size = os.path.getsize(local_filename)
                    
                    try:
                        with open(local_filename, 'rb') as f:
                            header = f.read(10)
                            if header.startswith(b'\x80\x02') or header.startswith(b'\x80\x03') or header.startswith(b'PK'):
                                st.success(f"ŸÖÿØŸÑ ÿ®ÿß ŸÖŸàŸÅŸÇ€åÿ™ ÿØÿßŸÜŸÑŸàÿØ ÿ¥ÿØ! ÿ≠ÿ¨ŸÖ: {file_size / (1024*1024):.1f} ŸÖ⁄Øÿßÿ®ÿß€åÿ™")
                                return local_filename
                            else:
                                st.warning(f"ÿ±Ÿàÿ¥ {i+1}: ŸÅÿß€åŸÑ ÿØÿßŸÜŸÑŸàÿØ ÿ¥ÿØŸá ŸÖÿπÿ™ÿ®ÿ± ŸÜ€åÿ≥ÿ™")
                                if os.path.exists(local_filename):
                                    os.remove(local_filename)
                    except Exception as e:
                        st.warning(f"ÿ±Ÿàÿ¥ {i+1}: ÿÆÿ∑ÿß ÿØÿ± ÿßÿπÿ™ÿ®ÿßÿ±ÿ≥ŸÜÿ¨€å ŸÅÿß€åŸÑ: {e}")
                        if os.path.exists(local_filename):
                            os.remove(local_filename)
                else:
                    st.warning(f"ÿ±Ÿàÿ¥ {i+1}: ŸÅÿß€åŸÑ ÿØÿßŸÜŸÑŸàÿØ ÿ¥ÿØŸá ÿÆÿßŸÑ€å ÿßÿ≥ÿ™")
                    if os.path.exists(local_filename):
                        os.remove(local_filename)
                        
            except Exception as e:
                st.warning(f"ÿ±Ÿàÿ¥ ÿØÿßŸÜŸÑŸàÿØ {i+1} ÿ®ÿß ÿÆÿ∑ÿß ŸÖŸàÿßÿ¨Ÿá ÿ¥ÿØ: {str(e)}")
                if os.path.exists(local_filename):
                    os.remove(local_filename)
                continue
        
        st.info("ÿ™ŸÖÿßŸÖ ÿ±Ÿàÿ¥‚ÄåŸáÿß€å gdown ŸÜÿßŸÖŸàŸÅŸÇ ÿ®ŸàÿØŸÜÿØ. ÿ™ŸÑÿßÿ¥ ÿ®ÿß ÿ±Ÿàÿ¥ ÿØÿ≥ÿ™€å...")
        return manual_download_fallback(correct_file_id, local_filename)
            
    except Exception as e:
        st.error(f"ÿÆÿ∑ÿß ÿØÿ± ÿ™ÿßÿ®ÿπ ÿØÿßŸÜŸÑŸàÿØ: {str(e)}")
        return None

def manual_download_fallback(file_id, local_filename):
    """
    Fallback manual download method using requests
    """
    try:
        import requests
        
        urls_to_try = [
            f"https://drive.google.com/uc?export=download&id={file_id}",
            f"https://drive.google.com/uc?export=download&id={file_id}&confirm=t",
            f"https://drive.usercontent.google.com/download?id={file_id}&export=download",
        ]
        
        session = requests.Session()
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        
        for i, url in enumerate(urls_to_try):
            try:
                st.info(f"ÿ±Ÿàÿ¥ ÿØÿ≥ÿ™€å {i+1} ÿßÿ≤ 3 ÿØÿ± ÿ≠ÿßŸÑ ÿßÿ¨ÿ±ÿß...")
                response = session.get(url, headers=headers, stream=True, timeout=30)
                
                if response.status_code == 200:
                    content_type = response.headers.get('content-type', '').lower()
                    
                    if 'text/html' not in content_type:
                        total_size = int(response.headers.get('content-length', 0))
                        downloaded_size = 0
                        
                        if total_size > 0:
                            progress_bar = st.progress(0)
                            status_text = st.empty()
                        
                        with open(local_filename, 'wb') as f:
                            for chunk in response.iter_content(chunk_size=8192):
                                if chunk:
                                    f.write(chunk)
                                    downloaded_size += len(chunk)
                                    
                                    if total_size > 0:
                                        progress = downloaded_size / total_size
                                        progress_bar.progress(progress)
                                        status_text.text(f"ÿØÿßŸÜŸÑŸàÿØ ÿ¥ÿØŸá: {downloaded_size / (1024*1024):.1f} MB / {total_size / (1024*1024):.1f} MB")
                        
                        if total_size > 0:
                            progress_bar.empty()
                            status_text.empty()
                        
                        if os.path.exists(local_filename) and os.path.getsize(local_filename) > 1024:
                            file_size = os.path.getsize(local_filename)
                            st.success(f"ÿØÿßŸÜŸÑŸàÿØ ÿØÿ≥ÿ™€å ŸÖŸàŸÅŸÇ€åÿ™‚Äåÿ¢ŸÖ€åÿ≤ ÿ®ŸàÿØ! ÿ≠ÿ¨ŸÖ: {file_size / (1024*1024):.1f} ŸÖ⁄Øÿßÿ®ÿß€åÿ™")
                            return local_filename
                    else:
                        st.warning(f"ÿ±Ÿàÿ¥ {i+1} ÿ®Ÿá ÿ¨ÿß€å ŸÅÿß€åŸÑÿå HTML ÿ®ÿ±⁄Øÿ±ÿØÿßŸÜÿØ")
                        
            except Exception as e:
                st.warning(f"ÿ±Ÿàÿ¥ ÿØÿ≥ÿ™€å {i+1} ÿ®ÿß ÿÆÿ∑ÿß ŸÖŸàÿßÿ¨Ÿá ÿ¥ÿØ: {e}")
                continue
        
        st.error("ÿ™ŸÖÿßŸÖ ÿ±Ÿàÿ¥‚ÄåŸáÿß€å ÿØÿßŸÜŸÑŸàÿØ ÿÆŸàÿØ⁄©ÿßÿ± ŸÜÿßŸÖŸàŸÅŸÇ ÿ®ŸàÿØŸÜÿØ. ŸÑÿ∑ŸÅÿßŸã ÿ®Ÿá ÿµŸàÿ±ÿ™ ÿØÿ≥ÿ™€å ÿØÿßŸÜŸÑŸàÿØ ⁄©ŸÜ€åÿØ:")
        
        st.info("**ÿ±ÿßŸáŸÜŸÖÿß€å ÿØÿßŸÜŸÑŸàÿØ ÿØÿ≥ÿ™€å:**")
        st.markdown(f"""
        1. **ÿß€åŸÜ ŸÑ€åŸÜ⁄© ÿ±ÿß ÿØÿ± ÿ™ÿ® ÿ¨ÿØ€åÿØ ŸÖÿ±Ÿàÿ±⁄Øÿ± ÿ®ÿßÿ≤ ⁄©ŸÜ€åÿØ:** 
           https://drive.google.com/file/d/{file_id}/view
        
        2. **ÿß⁄Øÿ± ÿÆÿ∑ÿß€å ÿØÿ≥ÿ™ÿ±ÿ≥€å ÿØ€åÿØ€åÿØ:**
           - ÿµÿßÿ≠ÿ® ŸÅÿß€åŸÑ ÿ®ÿß€åÿØ ÿßÿ¥ÿ™ÿ±ÿß⁄©‚Äå⁄Øÿ∞ÿßÿ±€å ÿ±ÿß ÿ®Ÿá "Ÿáÿ±⁄©ÿ≥€å ÿ®ÿß ŸÑ€åŸÜ⁄© ŸÖ€å‚Äåÿ™ŸàÿßŸÜÿØ ŸÖÿ¥ÿßŸáÿØŸá ⁄©ŸÜÿØ" ÿ™ÿ∫€å€åÿ± ÿØŸáÿØ
        
        3. **ÿ±Ÿà€å ÿØ⁄©ŸÖŸá ÿØÿßŸÜŸÑŸàÿØ ⁄©ŸÑ€å⁄© ⁄©ŸÜ€åÿØ**
        
        4. **ŸÅÿß€åŸÑ ÿ±ÿß ÿ®ÿß ŸÜÿßŸÖ ÿ≤€åÿ± ÿ∞ÿÆ€åÿ±Ÿá ⁄©ŸÜ€åÿØ:** `{local_filename}`
        
        5. **ÿßÿ≤ ÿ®ÿÆÿ¥ ÿ≤€åÿ± ÿ¢ŸæŸÑŸàÿØ ⁄©ŸÜ€åÿØ**
        """)
        
        uploaded_file = st.file_uploader(
            f"ŸÅÿß€åŸÑ ŸÖÿØŸÑ ({local_filename}) ÿ±ÿß Ÿæÿ≥ ÿßÿ≤ ÿØÿßŸÜŸÑŸàÿØ ÿØÿ≥ÿ™€å ÿ¢ŸæŸÑŸàÿØ ⁄©ŸÜ€åÿØ:",
            type=['pt', 'pth'],
            help="ŸÅÿß€åŸÑ ÿ±ÿß ÿ®Ÿá ÿµŸàÿ±ÿ™ ÿØÿ≥ÿ™€å ÿßÿ≤ Google Drive ÿØÿßŸÜŸÑŸàÿØ ⁄©ÿ±ÿØŸá Ÿà ÿß€åŸÜÿ¨ÿß ÿ¢ŸæŸÑŸàÿØ ⁄©ŸÜ€åÿØ"
        )
        
        if uploaded_file is not None:
            with open(local_filename, 'wb') as f:
                f.write(uploaded_file.read())
            
            file_size = os.path.getsize(local_filename)
            st.success(f"ŸÖÿØŸÑ ÿ®ÿß ŸÖŸàŸÅŸÇ€åÿ™ ÿ¢ŸæŸÑŸàÿØ ÿ¥ÿØ! ÿ≠ÿ¨ŸÖ: {file_size / (1024*1024):.1f} ŸÖ⁄Øÿßÿ®ÿß€åÿ™")
            return local_filename
        
        return None
        
    except Exception as e:
        st.error(f"ÿØÿßŸÜŸÑŸàÿØ ÿØÿ≥ÿ™€å ÿ®ÿß ÿÆÿ∑ÿß ŸÖŸàÿßÿ¨Ÿá ÿ¥ÿØ: {e}")
        return None

# Model loading section
gdrive_model_url = "https://drive.google.com/file/d/1m6EScw-mpBIvWV78h4pyjWq1OLQtn2ov/view?usp=drive_link"
model_path = "best_model_version_Unet++_v02_e7.pt"

if not os.path.exists(model_path):
    st.info("ŸÖÿØŸÑ ÿ®Ÿá ÿµŸàÿ±ÿ™ ŸÖÿ≠ŸÑ€å €åÿßŸÅÿ™ ŸÜÿ¥ÿØ. ÿØÿ± ÿ≠ÿßŸÑ ÿØÿßŸÜŸÑŸàÿØ ÿßÿ≤ Google Drive...")
    
    downloaded_model_path = download_model_from_gdrive(gdrive_model_url, model_path)
    
    if downloaded_model_path is None:
        st.error("ÿØÿßŸÜŸÑŸàÿØ ÿÆŸàÿØ⁄©ÿßÿ± ŸÜÿßŸÖŸàŸÅŸÇ ÿ®ŸàÿØ. ŸÑÿ∑ŸÅÿßŸã ÿßÿ≤ ⁄Øÿ≤€åŸÜŸá ÿØÿßŸÜŸÑŸàÿØ ÿØÿ≥ÿ™€å ÿßÿ≥ÿ™ŸÅÿßÿØŸá ⁄©ŸÜ€åÿØ.")
        st.stop()
else:
    st.success("ŸÖÿØŸÑ ÿ®Ÿá ÿµŸàÿ±ÿ™ ŸÖÿ≠ŸÑ€å €åÿßŸÅÿ™ ÿ¥ÿØ!")

# Verify the model file
if os.path.exists(model_path):
    try:
        file_size = os.path.getsize(model_path)
        st.info(f"ÿ≠ÿ¨ŸÖ ŸÅÿß€åŸÑ ŸÖÿØŸÑ: {file_size / (1024*1024):.1f} ŸÖ⁄Øÿßÿ®ÿß€åÿ™")
        
        with open(model_path, 'rb') as f:
            header = f.read(10)
            if not (header.startswith(b'\x80\x02') or header.startswith(b'\x80\x03') or header.startswith(b'PK')):
                st.error("ŸÅÿß€åŸÑ ŸÖÿØŸÑ ÿÆÿ±ÿßÿ® €åÿß ŸÜÿßŸÖÿπÿ™ÿ®ÿ± ÿßÿ≥ÿ™.")
                st.error(f"ŸáÿØÿ± ŸÅÿß€åŸÑ: {header}")
                st.info("ŸÑÿ∑ŸÅÿßŸã ŸÅÿß€åŸÑ ŸÖÿØŸÑ ÿ±ÿß ŸÖÿ¨ÿØÿØÿßŸã ÿØÿßŸÜŸÑŸàÿØ ⁄©ŸÜ€åÿØ.")
                
                try:
                    with open(model_path, 'r', encoding='utf-8', errors='ignore') as f:
                        content = f.read(200)
                        st.code(content, language='text')
                except:
                    pass
                
                os.remove(model_path)
                st.stop()
            else:
                st.success("ŸÅÿß€åŸÑ ŸÖÿØŸÑ ŸÖÿπÿ™ÿ®ÿ± ÿßÿ≥ÿ™!")
                
    except Exception as e:
        st.error(f"ÿÆÿ∑ÿß ÿØÿ± ÿßÿπÿ™ÿ®ÿßÿ±ÿ≥ŸÜÿ¨€å ŸÅÿß€åŸÑ ŸÖÿØŸÑ: {e}")
        st.stop()

# Install GEES2Downloader if not already installed
try:
    from geeS2downloader.geeS2downloader import GEES2Downloader
    st.sidebar.success("GEES2Downloader ŸÜÿµÿ® ÿ¥ÿØŸá ÿßÿ≥ÿ™.")
except ImportError:
    st.sidebar.info("ÿØÿ± ÿ≠ÿßŸÑ ŸÜÿµÿ® GEES2Downloader...")
    try:
        subprocess.check_call([
            sys.executable, "-m", "pip", "install", 
            "git+https://github.com/cordmaur/GEES2Downloader.git"
        ])
        
        from geeS2downloader.geeS2downloader import GEES2Downloader
        st.sidebar.success("GEES2Downloader ÿ®ÿß ŸÖŸàŸÅŸÇ€åÿ™ ŸÜÿµÿ® ÿ¥ÿØ!")
    except Exception as e:
        st.sidebar.error(f"ŸÜÿµÿ® GEES2Downloader ŸÜÿßŸÖŸàŸÅŸÇ ÿ®ŸàÿØ: {str(e)}")
        st.sidebar.info("ŸÑÿ∑ŸÅÿßŸã GEES2Downloader ÿ±ÿß ÿ®Ÿá ÿµŸàÿ±ÿ™ ÿØÿ≥ÿ™€å ŸÜÿµÿ® ⁄©ŸÜ€åÿØ")

# Initialize Earth Engine
@st.cache_resource
def initialize_earth_engine():
    try:
        ee.Initialize()
        return True, "Earth Engine ÿ¢ŸÖÿßÿØŸá ÿßÿ≥ÿ™"
    except Exception as e:
        try:
            base64_key = os.environ.get('GOOGLE_EARTH_ENGINE_KEY_BASE64')
            
            if not base64_key:
                return False, "⁄©ŸÑ€åÿØ ÿ≥ÿ±Ÿà€åÿ≥ Earth Engine ÿØÿ± ŸÖÿ™ÿ∫€åÿ±Ÿáÿß€å ŸÖÿ≠€åÿ∑€å €åÿßŸÅÿ™ ŸÜÿ¥ÿØ."
            
            key_json = base64.b64decode(base64_key).decode()
            key_data = json.loads(key_json)
            
            key_file = tempfile.NamedTemporaryFile(suffix='.json', delete=False)
            with open(key_file.name, 'w') as f:
                json.dump(key_data, f)
            
            credentials = ee.ServiceAccountCredentials(
                key_data['client_email'],
                key_file.name
            )
            ee.Initialize(credentials)
            
            os.unlink(key_file.name)
            
            return True, "ÿßÿ≠ÿ±ÿßÿ≤ ŸáŸà€åÿ™ Earth Engine ŸÖŸàŸÅŸÇ€åÿ™‚Äåÿ¢ŸÖ€åÿ≤ ÿ®ŸàÿØ!"
        except Exception as auth_error:
            return False, f"ÿßÿ≠ÿ±ÿßÿ≤ ŸáŸà€åÿ™ ŸÜÿßŸÖŸàŸÅŸÇ ÿ®ŸàÿØ: {str(auth_error)}"

ee_initialized, ee_message = initialize_earth_engine()
if ee_initialized:
    st.sidebar.success(ee_message)
else:
    st.sidebar.error(ee_message)
    st.error("ÿßÿ≠ÿ±ÿßÿ≤ ŸáŸà€åÿ™ Earth Engine ÿ®ÿ±ÿß€å ÿßÿ≥ÿ™ŸÅÿßÿØŸá ÿßÿ≤ ÿß€åŸÜ ÿ®ÿ±ŸÜÿßŸÖŸá ÿ∂ÿ±Ÿàÿ±€å ÿßÿ≥ÿ™.")
    st.info("""
    ŸÑÿ∑ŸÅÿßŸã ŸÖÿ™ÿ∫€åÿ± ŸÖÿ≠€åÿ∑€å GOOGLE_EARTH_ENGINE_KEY_BASE64 ÿ±ÿß ÿ®ÿß ⁄©ŸÑ€åÿØ ÿ≠ÿ≥ÿßÿ® ÿ≥ÿ±Ÿà€åÿ≥ ÿÆŸàÿØ ÿ™ŸÜÿ∏€åŸÖ ⁄©ŸÜ€åÿØ.
    
    1. €å⁄© ÿ≠ÿ≥ÿßÿ® ÿ≥ÿ±Ÿà€åÿ≥ ÿØÿ± Google Cloud Console ÿß€åÿ¨ÿßÿØ ⁄©ŸÜ€åÿØ
    2. €å⁄© ⁄©ŸÑ€åÿØ JSON ÿ®ÿ±ÿß€å ÿ≠ÿ≥ÿßÿ® ÿ≥ÿ±Ÿà€åÿ≥ ÿ™ŸàŸÑ€åÿØ ⁄©ŸÜ€åÿØ
    3. ⁄©ŸÑ€åÿØ JSON ÿ±ÿß ÿ®Ÿá base64 ÿ™ÿ®ÿØ€åŸÑ ⁄©ŸÜ€åÿØ
    4. ÿ¢ŸÜ ÿ±ÿß ÿ®Ÿá ÿπŸÜŸàÿßŸÜ ŸÖÿ™ÿ∫€åÿ± ŸÖÿ≠€åÿ∑€å ÿØÿ± Posit Cloud ÿ™ŸÜÿ∏€åŸÖ ⁄©ŸÜ€åÿØ
    """)
    st.stop()

# Main title
st.markdown("<h1 style='text-align: center; color: #2c3e50;'>üèóÔ∏è ÿ≥€åÿ≥ÿ™ŸÖ ÿ™ÿ¥ÿÆ€åÿµ ÿ™ÿ∫€å€åÿ±ÿßÿ™ ÿ≥ÿßÿÆÿ™ŸÖÿßŸÜ€å ÿ®ÿß ÿ™ÿµÿßŸà€åÿ± ŸÖÿßŸáŸàÿßÿ±Ÿá‚Äåÿß€å</h1>", unsafe_allow_html=True)

# Create tabs for different pages
tab1, tab2, tab3, tab4 = st.tabs([
    "üó∫Ô∏è ÿßŸÜÿ™ÿÆÿßÿ® ŸÖŸÜÿ∑ŸÇŸá", 
    "üìÖ ÿ™ÿµŸà€åÿ± ŸÇÿ®ŸÑ", 
    "üìÖ ÿ™ÿµŸà€åÿ± ÿ®ÿπÿØ", 
    "üîç ÿ™ÿ¥ÿÆ€åÿµ ÿ™ÿ∫€å€åÿ±ÿßÿ™"
])

# Global variables
if 'drawn_polygons' not in st.session_state:
    st.session_state.drawn_polygons = []

if 'last_map_data' not in st.session_state:
    st.session_state.last_map_data = None

if 'clipped_img' not in st.session_state:
    st.session_state.clipped_img = None
    
if 'clipped_img_2024' not in st.session_state:
    st.session_state.clipped_img_2024 = None

if 'model_loaded' not in st.session_state:
    st.session_state.model_loaded = False
    
if 'saved_patches_paths' not in st.session_state:
    st.session_state.saved_patches_paths = []
    
if 'saved_patches_paths_2024' not in st.session_state:
    st.session_state.saved_patches_paths_2024 = []

if 'change_detection_result' not in st.session_state:
    st.session_state.change_detection_result = None

# Define Sentinel-2 bands
S2_BANDS = ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B9', 'B11', 'B12']
S2_NAMES = ['ÿ¢ÿ¶ÿ±Ÿàÿ≥ŸÑ', 'ÿ¢ÿ®€å', 'ÿ≥ÿ®ÿ≤', 'ŸÇÿ±ŸÖÿ≤', 'ŸÑÿ®Ÿá ŸÇÿ±ŸÖÿ≤ 1', 'ŸÑÿ®Ÿá ŸÇÿ±ŸÖÿ≤ 2', 
           'ŸÑÿ®Ÿá ŸÇÿ±ŸÖÿ≤ 3', 'NIR', 'ŸÑÿ®Ÿá ŸÇÿ±ŸÖÿ≤ 4', 'ÿ®ÿÆÿßÿ± ÿ¢ÿ®', 'SWIR1', 'SWIR2']

# [Keep all the existing functions unchanged - download_sentinel2_with_gees2, normalized, 
# get_utm_zone, get_utm_epsg, convert_to_utm, apply_erosion, load_model, process_image]

# I'll continue with the function definitions in the next part...
# [Previous functions remain the same, just continuing from here]

def download_sentinel2_with_gees2(year, polygon, start_month, end_month, cloud_cover_limit=10):
    status_placeholder = st.empty()
    progress_placeholder = st.empty()
    
    try:
        start_date = f"{year}-{start_month:02d}-01"
        
        if end_month in [4, 6, 9, 11]:
            end_day = 30
        elif end_month == 2:
            end_day = 29 if int(year) % 4 == 0 else 28
        else:
            end_day = 31
            
        end_date = f"{year}-{end_month:02d}-{end_day}"
        
        area_sq_km = polygon.area * 111 * 111
        status_placeholder.info(f"ŸÖÿ≥ÿßÿ≠ÿ™ ŸÖŸÜÿ∑ŸÇŸá ÿßŸÜÿ™ÿÆÿßÿ®€å: ~{area_sq_km:.2f} ⁄©€åŸÑŸàŸÖÿ™ÿ± ŸÖÿ±ÿ®ÿπ. ÿØÿ± ÿ≠ÿßŸÑ ÿ¨ÿ≥ÿ™ÿ¨Ÿà€å ÿ™ÿµÿßŸà€åÿ±...")
        
        temp_dir = tempfile.mkdtemp()
        output_file = os.path.join(temp_dir, f"sentinel2_{year}_{start_month:02d}_{end_month:02d}_median.tif")
        
        geojson = {"type": "Polygon", "coordinates": [list(polygon.exterior.coords)]}
        ee_geometry = ee.Geometry.Polygon(geojson['coordinates'])
        
        status_placeholder.info(f"ÿß€åÿ¨ÿßÿØ ŸÖÿ¨ŸÖŸàÿπŸá ÿ™ÿµÿßŸà€åÿ± ÿ®ÿ±ÿß€å {start_date} ÿ™ÿß {end_date} ÿ®ÿß ŸæŸàÿ¥ÿ¥ ÿßÿ®ÿ± < {cloud_cover_limit}%...")
        
        collection = (ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')
                     .filterBounds(ee_geometry)
                     .filterDate(start_date, end_date)
                     .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', cloud_cover_limit)))
        
        count = collection.size().getInfo()
        status_placeholder.info(f"{count} ÿ™ÿµŸà€åÿ± ÿ®ÿß ŸæŸàÿ¥ÿ¥ ÿßÿ®ÿ± < {cloud_cover_limit}% €åÿßŸÅÿ™ ÿ¥ÿØ")
        
        if count == 0:
            status_placeholder.warning(f"Ÿá€å⁄Ü ÿ™ÿµŸà€åÿ±€å ÿ®ÿ±ÿß€å {year} ÿ®ÿß ŸæŸàÿ¥ÿ¥ ÿßÿ®ÿ± < {cloud_cover_limit}% €åÿßŸÅÿ™ ŸÜÿ¥ÿØ")
            
            higher_limit = min(cloud_cover_limit * 2, 100)
            status_placeholder.info(f"ÿ™ŸÑÿßÿ¥ ÿ®ÿß ŸÖÿ≠ÿØŸàÿØ€åÿ™ ÿßÿ®ÿ± ÿ®ÿßŸÑÿßÿ™ÿ± ({higher_limit}%)...")
            
            collection = (ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')
                         .filterBounds(ee_geometry)
                         .filterDate(start_date, end_date)
                         .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', higher_limit)))
            
            count = collection.size().getInfo()
            status_placeholder.info(f"{count} ÿ™ÿµŸà€åÿ± ÿ®ÿß ŸæŸàÿ¥ÿ¥ ÿßÿ®ÿ± < {higher_limit}% €åÿßŸÅÿ™ ÿ¥ÿØ")
            
            if count == 0:
                status_placeholder.error(f"ÿ≠ÿ™€å ÿ®ÿß ŸÖÿ≠ÿØŸàÿØ€åÿ™ ÿßÿ®ÿ± ÿ®ÿßŸÑÿßÿ™ÿ± Ÿá€å⁄Ü ÿ™ÿµŸà€åÿ±€å €åÿßŸÅÿ™ ŸÜÿ¥ÿØ.")
                return None
        
        status_placeholder.info(f"ÿß€åÿ¨ÿßÿØ ÿ™ÿ±⁄©€åÿ® ŸÖ€åÿßŸÜŸá ÿßÿ≤ {count} ÿ™ÿµŸà€åÿ±...")
        median_image = collection.median().select(S2_BANDS)
        
        def progress_callback(progress):
            progress_placeholder.progress(progress)
        
        bands_dir = os.path.join(temp_dir, "bands")
        os.makedirs(bands_dir, exist_ok=True)
        
        status_placeholder.info("ÿØÿßŸÜŸÑŸàÿØ ÿ®ÿßŸÜÿØŸáÿß...")
        band_files = []
        
        region = ee_geometry.bounds().getInfo()['coordinates']
        
        for i, band in enumerate(S2_BANDS):
            try:
                status_placeholder.info(f"ÿØÿßŸÜŸÑŸàÿØ ÿ®ÿßŸÜÿØ {band} ({i+1}/{len(S2_BANDS)})...")
                
                band_file = os.path.join(bands_dir, f"{band}.tif")
                
                url = median_image.select(band).getDownloadURL({
                    'scale': 10,
                    'region': region,
                    'format': 'GEO_TIFF',
                    'bands': [band]
                })
                
                response = requests.get(url, stream=True)
                if response.status_code == 200:
                    with open(band_file, 'wb') as f:
                        for chunk in response.iter_content(chunk_size=8192):
                            if chunk:
                                f.write(chunk)
                    
                    band_files.append(band_file)
                    progress_callback((i + 1) / len(S2_BANDS))
                else:
                    status_placeholder.error(f"ÿØÿßŸÜŸÑŸàÿØ ÿ®ÿßŸÜÿØ {band} ŸÜÿßŸÖŸàŸÅŸÇ ÿ®ŸàÿØ")
            except Exception as e:
                status_placeholder.error(f"ÿÆÿ∑ÿß ÿØÿ± ÿØÿßŸÜŸÑŸàÿØ ÿ®ÿßŸÜÿØ {band}: {str(e)}")
        
        if len(band_files) == len(S2_BANDS):
            status_placeholder.info("ÿ™ŸÖÿßŸÖ ÿ®ÿßŸÜÿØŸáÿß ÿØÿßŸÜŸÑŸàÿØ ÿ¥ÿØŸÜÿØ. ÿß€åÿ¨ÿßÿØ GeoTIFF ⁄ÜŸÜÿØÿ®ÿßŸÜÿØ€å...")
            
            with rasterio.open(band_files[0]) as src:
                meta = src.meta.copy()
            
            meta.update(count=len(band_files))
            
            with rasterio.open(output_file, 'w', **meta) as dst:
                for i, band_file in enumerate(band_files):
                    with rasterio.open(band_file) as src:
                        dst.write(src.read(1), i+1)
            
            status_placeholder.success("GeoTIFF ⁄ÜŸÜÿØÿ®ÿßŸÜÿØ€å ÿ®ÿß ŸÖŸàŸÅŸÇ€åÿ™ ÿß€åÿ¨ÿßÿØ ÿ¥ÿØ")
            return output_file
        else:
            status_placeholder.error(f"ÿ™ŸÜŸáÿß {len(band_files)}/{len(S2_BANDS)} ÿ®ÿßŸÜÿØ ÿØÿßŸÜŸÑŸàÿØ ÿ¥ÿØ")
            return None
        
    except Exception as e:
        status_placeholder.error(f"ÿÆÿ∑ÿß ÿØÿ± ÿØÿßŸÜŸÑŸàÿØ ÿØÿßÿØŸá: {str(e)}")
        import traceback
        st.error(traceback.format_exc())
        return None

def normalized(img):
    min_val = np.nanmin(img)
    max_val = np.nanmax(img)
    
    if max_val == min_val:
        return np.zeros_like(img)
    
    img_norm = (img - min_val) / (max_val - min_val)
    return img_norm

def get_utm_zone(longitude):
    return math.floor((longitude + 180) / 6) + 1

def get_utm_epsg(longitude, latitude):
    zone_number = get_utm_zone(longitude)
    
    if latitude >= 0:
        return f"EPSG:326{zone_number:02d}"
    else:
        return f"EPSG:327{zone_number:02d}"

def convert_to_utm(src_path, dst_path, polygon=None):
    with rasterio.open(src_path) as src:
        if polygon:
            centroid = polygon.centroid
            lon, lat = centroid.x, centroid.y
            dst_crs = get_utm_epsg(lon, lat)
            st.info(f"ÿ≤ŸàŸÜ UTM ÿ™ÿ¥ÿÆ€åÿµ ÿØÿßÿØŸá ÿ¥ÿØŸá: {get_utm_zone(lon)} ({dst_crs})")
        else:
            bounds = src.bounds
            center_lon = (bounds.left + bounds.right) / 2
            center_lat = (bounds.bottom + bounds.top) / 2
            dst_crs = get_utm_epsg(center_lon, center_lat)
            st.info(f"ÿ≤ŸàŸÜ UTM ÿ™ÿ¥ÿÆ€åÿµ ÿØÿßÿØŸá ÿ¥ÿØŸá: {get_utm_zone(center_lon)} ({dst_crs})")
        
        transform, width, height = calculate_default_transform(
            src.crs, dst_crs, src.width, src.height, *src.bounds)
        
        kwargs = src.meta.copy()
        kwargs.update({
            'crs': dst_crs,
            'transform': transform,
            'width': width,
            'height': height
        })
        
        with rasterio.open(dst_path, 'w', **kwargs) as dst:
            for i in range(1, src.count + 1):
                reproject(
                    source=rasterio.band(src, i),
                    destination=rasterio.band(dst, i),
                    src_transform=src.transform,
                    src_crs=src.crs,
                    dst_transform=transform,
                    dst_crs=dst_crs,
                    resampling=Resampling.nearest
                )
        
        return dst_path, dst_crs

def apply_erosion(image, kernel_size):
    kernel = np.ones((kernel_size, kernel_size), dtype=np.uint8)
    eroded_image = ndimage.binary_erosion(image, structure=kernel).astype(image.dtype)
    return eroded_image

@st.cache_resource
def load_model(model_path):
    try:
        device = torch.device('cpu')
        model = smp.UnetPlusPlus(
            encoder_name='timm-efficientnet-b7',
            encoder_weights='imagenet',
            in_channels=12,
            classes=1,
            decoder_attention_type='scse'
        ).to(device)

        loaded_object = torch.load(model_path, map_location=device, weights_only=False)

        if isinstance(loaded_object, dict) and 'model_state_dict' in loaded_object:
            model.load_state_dict(loaded_object['model_state_dict'])
            st.info("ŸÖÿØŸÑ ÿßÿ≤ ÿØ€å⁄©ÿ¥ŸÜÿ±€å checkpoint ÿ®ÿßÿ±⁄Øÿ∞ÿßÿ±€å ÿ¥ÿØ.")
        elif isinstance(loaded_object, dict):
            model.load_state_dict(loaded_object)
            st.info("ŸÖÿØŸÑ ŸÖÿ≥ÿ™ŸÇ€åŸÖÿßŸã ÿßÿ≤ state_dict ÿ®ÿßÿ±⁄Øÿ∞ÿßÿ±€å ÿ¥ÿØ.")
        else:
            st.error("ŸÅÿ±ŸÖÿ™ ŸÅÿß€åŸÑ ŸÖÿØŸÑ ŸÇÿßÿ®ŸÑ ÿ¥ŸÜÿßÿ≥ÿß€å€å ŸÜ€åÿ≥ÿ™.")
            st.session_state.model_loaded = False
            return None, None

        model.eval()
        st.session_state.model_loaded = True
        st.success("ŸÖÿØŸÑ ÿ®ÿß ŸÖŸàŸÅŸÇ€åÿ™ ÿ®ÿßÿ±⁄Øÿ∞ÿßÿ±€å ÿ¥ÿØ!")
        return model, device
    except Exception as e:
        st.error(f"ÿÆÿ∑ÿß ÿØÿ± ÿ®ÿßÿ±⁄Øÿ∞ÿßÿ±€å ŸÖÿØŸÑ: {str(e)}")
        st.session_state.model_loaded = False
        return None, None

def process_image(image_path, year, selected_polygon, region_number):
    progress_placeholder = st.empty()
    status_placeholder = st.empty()
    
    try:
        # Step 1: Clipping
        status_placeholder.info("ŸÖÿ±ÿ≠ŸÑŸá 1 ÿßÿ≤ 4: ÿ®ÿ±ÿ¥ ÿ™ÿµŸà€åÿ±...")
        progress_placeholder.progress(0)
        
        with rasterio.open(image_path) as src:
            raster_bounds = box(*src.bounds)
            polygon_shapely = selected_polygon
            
            if not raster_bounds.intersects(polygon_shapely):
                status_placeholder.error("ÿÆÿ∑ÿß: ŸÖŸÜÿ∑ŸÇŸá ÿßŸÜÿ™ÿÆÿßÿ®€å ÿ®ÿß ÿ™ÿµŸà€åÿ± ÿØÿßŸÜŸÑŸàÿØ ÿ¥ÿØŸá ŸáŸÖŸæŸàÿ¥ÿßŸÜ€å ŸÜÿØÿßÿ±ÿØ.")
                return False
            
            geoms = [mapping(selected_polygon)]
            
            try:
                clipped_img, clipped_transform = mask(src, geoms, crop=True)
                
                if clipped_img.size == 0 or np.all(clipped_img == 0):
                    status_placeholder.error("ÿÆÿ∑ÿß: ÿ®ÿ±ÿ¥ ÿ™ÿµŸà€åÿ± ÿÆÿßŸÑ€å ÿßÿ≥ÿ™.")
                    return False
                
            except ValueError as e:
                if "Input shapes do not overlap raster" in str(e):
                    status_placeholder.error("ÿÆÿ∑ÿß: ŸÖŸÜÿ∑ŸÇŸá ÿßŸÜÿ™ÿÆÿßÿ®€å ÿ®ÿß ÿØÿßÿØŸá‚ÄåŸáÿß€å ŸÖÿπÿ™ÿ®ÿ± ÿØÿ± ÿ™ÿµŸà€åÿ± ŸáŸÖŸæŸàÿ¥ÿßŸÜ€å ŸÜÿØÿßÿ±ÿØ.")
                    return False
                else:
                    raise
            
            clipped_meta = src.meta.copy()
            clipped_meta.update({
                "height": clipped_img.shape[1],
                "width": clipped_img.shape[2],
                "transform": clipped_transform
            })
            
            temp_dir = os.path.dirname(image_path)
            os.makedirs(os.path.join(temp_dir, "temp"), exist_ok=True)
            temp_clipped_path = os.path.join(temp_dir, "temp", f"temp_clipped_{year}_region{region_number}.tif")
            
            with rasterio.open(temp_clipped_path, 'w', **clipped_meta) as dst:
                dst.write(clipped_img)
            
            utm_clipped_path = os.path.join(temp_dir, "temp", f"utm_clipped_{year}_region{region_number}.tif")
            utm_path, utm_crs = convert_to_utm(temp_clipped_path, utm_clipped_path, selected_polygon)
            
            with rasterio.open(utm_path) as src_utm:
                clipped_img = src_utm.read()
                clipped_meta = src_utm.meta.copy()
            
            if year == st.session_state.before_year:
                st.session_state.clipped_img = clipped_img
                st.session_state.clipped_meta = clipped_meta
                st.session_state.region_number = region_number
                st.session_state.year = year
            else:
                st.session_state.clipped_img_2024 = clipped_img
                st.session_state.clipped_meta_2024 = clipped_meta
                st.session_state.region_number_2024 = region_number
                st.session_state.year_2024 = year
            
            if clipped_img.shape[1] < 300 or clipped_img.shape[2] < 300:
                status_placeholder.error(f"ÿ™ÿµŸà€åÿ± ÿ®ÿ±ÿ¥‚ÄåÿÆŸàÿ±ÿØŸá ÿ®ÿ≥€åÿßÿ± ⁄©Ÿà⁄Ü⁄© ÿßÿ≥ÿ™ ({clipped_img.shape[1]}x{clipped_img.shape[2]} Ÿæ€å⁄©ÿ≥ŸÑ).")
                return False
            
            rgb_bands = [3, 2, 1]
            
            if clipped_img.shape[0] >= 3:
                rgb = np.zeros((clipped_img.shape[1], clipped_img.shape[2], 3), dtype=np.float32)
                
                for i, band in enumerate(rgb_bands):
                    if band < clipped_img.shape[0]:
                        band_data = clipped_img[band]
                        min_val = np.percentile(band_data, 2)
                        max_val = np.percentile(band_data, 98)
                        rgb[:, :, i] = np.clip((band_data - min_val) / (max_val - min_val), 0, 1)
                
                fig, ax = plt.subplots(figsize=(10, 10))
                ax.imshow(rgb)
                ax.set_title(f"ÿ™ÿµŸà€åÿ± ÿ®ÿ±ÿ¥‚ÄåÿÆŸàÿ±ÿØŸá ÿ≥ŸÜÿ™€åŸÜŸÑ-2 ÿ≥ÿßŸÑ {year}")
                ax.axis('off')
                st.pyplot(fig)
            
            progress_placeholder.progress(25)
            status_placeholder.success("ŸÖÿ±ÿ≠ŸÑŸá 1 ÿßÿ≤ 4: ÿ®ÿ±ÿ¥ ÿ®ÿß ŸÖŸàŸÅŸÇ€åÿ™ ÿßŸÜÿ¨ÿßŸÖ ÿ¥ÿØ")
        
        # Step 2: Patching
        status_placeholder.info("ŸÖÿ±ÿ≠ŸÑŸá 2 ÿßÿ≤ 4: ÿß€åÿ¨ÿßÿØ ÿ™⁄©Ÿá‚ÄåŸáÿß€å ÿ™ÿµŸà€åÿ±...")
        
        img_for_patching = np.moveaxis(clipped_img, 0, -1)
        
        patch_size = 224
        patches = patchify(img_for_patching, (patch_size, patch_size, clipped_img.shape[0]), step=patch_size)
        patches = patches.squeeze()
        
        base_dir = os.path.dirname(image_path)
        output_folder = os.path.join(base_dir, f"patches_{year}_region{region_number}")
        os.makedirs(output_folder, exist_ok=True)
        
        num_patches = patches.shape[0] * patches.shape[1]
        saved_paths = []
        
        patch_progress = st.progress(0)
        
        for i in range(patches.shape[0]):
            for j in range(patches.shape[1]):
                patch = patches[i, j]
                patch_normalized = normalized(patch)
                patch_for_saving = np.moveaxis(patch_normalized, -1, 0)
                
                patch_name = f"region{region_number}_{i}_{j}.tif"
                output_file_path = os.path.join(output_folder, patch_name)
                saved_paths.append(output_file_path)
                
                with rasterio.open(
                    output_file_path, 'w', driver='GTiff',
                    height=patch_size, width=patch_size,
                    count=patch_for_saving.shape[0], dtype='float64',
                    crs=clipped_meta.get('crs'),
                    transform=clipped_meta.get('transform')
                ) as dst:
                    for band_idx in range(patch_for_saving.shape[0]):
                        band_data = patch_for_saving[band_idx].reshape(patch_size, patch_size)
                        dst.write(band_data, band_idx+1)
                
                patch_count = i * patches.shape[1] + j + 1
                patch_progress.progress(patch_count / num_patches)
        
        if year == st.session_state.before_year:
            st.session_state.saved_patches_paths = saved_paths
            st.session_state.patches_shape = patches.shape
            st.session_state.patches_info = {
                'year': year, 'region_number': region_number,
                'output_folder': output_folder, 'patch_size': patch_size
            }
        else:
            st.session_state.saved_patches_paths_2024 = saved_paths
            st.session_state.patches_shape_2024 = patches.shape
            st.session_state.patches_info_2024 = {
                'year': year, 'region_number': region_number,
                'output_folder': output_folder, 'patch_size': patch_size
            }
        
        num_samples = min(6, num_patches)
        if num_samples > 0:
            st.subheader("ŸÜŸÖŸàŸÜŸá ÿ™⁄©Ÿá‚ÄåŸáÿß€å ÿ™ÿµŸà€åÿ±")
            fig, axes = plt.subplots(1, num_samples, figsize=(15, 4))
            if num_samples == 1:
                axes = [axes]
            
            for idx, ax in enumerate(axes):
                if idx < num_patches:
                    i, j = idx // patches.shape[1], idx % patches.shape[1]
                    patch = patches[i, j]
                    
                    rgb_bands = [3, 2, 1]
                    patch_rgb = np.zeros((patch_size, patch_size, 3), dtype=np.float32)
                    for b, band in enumerate(rgb_bands):
                        if band < patch.shape[-1]:
                            band_data = patch[:, :, band]
                            min_val = np.percentile(band_data, 2)
                            max_val = np.percentile(band_data, 98)
                            patch_rgb[:, :, b] = np.clip((band_data - min_val) / (max_val - min_val), 0, 1)
                    
                    ax.imshow(patch_rgb)
                    ax.set_title(f"ÿ™⁄©Ÿá {i}_{j}")
                    ax.axis('off')
            
            st.pyplot(fig)
        
        progress_placeholder.progress(50)
        status_placeholder.success(f"ŸÖÿ±ÿ≠ŸÑŸá 2 ÿßÿ≤ 4: {num_patches} ÿ™⁄©Ÿá ÿ®ÿß ŸÖŸàŸÅŸÇ€åÿ™ ÿß€åÿ¨ÿßÿØ ÿ¥ÿØ")
        
        # Step 3: Classification
        status_placeholder.info("ŸÖÿ±ÿ≠ŸÑŸá 3 ÿßÿ≤ 4: ÿ∑ÿ®ŸÇŸá‚Äåÿ®ŸÜÿØ€å ÿ™⁄©Ÿá‚ÄåŸáÿß...")
        
        if not st.session_state.model_loaded:
            with st.spinner("ÿ®ÿßÿ±⁄Øÿ∞ÿßÿ±€å ŸÖÿØŸÑ..."):
                model, device = load_model(model_path)
                if model is not None:
                    st.session_state.model = model
                    st.session_state.device = device
                    st.session_state.model_loaded = True
                else:
                    status_placeholder.error("ÿ®ÿßÿ±⁄Øÿ∞ÿßÿ±€å ŸÖÿØŸÑ ŸÜÿßŸÖŸàŸÅŸÇ ÿ®ŸàÿØ.")
                    return False
        
        if year == st.session_state.before_year:
            patches_info = st.session_state.patches_info
            saved_paths = st.session_state.saved_patches_paths
            patches_shape = st.session_state.patches_shape
        else:
            patches_info = st.session_state.patches_info_2024
            saved_paths = st.session_state.saved_patches_paths_2024
            patches_shape = st.session_state.patches_shape_2024
        
        base_dir = os.path.dirname(image_path)
        classified_folder = os.path.join(base_dir, f"classified_{year}_region{region_number}")
        os.makedirs(classified_folder, exist_ok=True)
        
        classified_results = []
        classified_paths = []
        
        classify_progress = st.progress(0)
        
        total_patches = len(saved_paths)
        for idx, patch_path in enumerate(saved_paths):
            try:
                filename = os.path.basename(patch_path)
                i_j_part = filename.split('_')[-2:]
                i = int(i_j_part[0])
                j = int(i_j_part[1].split('.')[0])
                
                with rasterio.open(patch_path) as src:
                    patch = src.read()
                    patch_meta = src.meta.copy()
                
                rgb_bands = [3, 2, 1]
                if patch.shape[0] >= 3:
                    rgb_patch = np.zeros((patch.shape[1], patch.shape[2], 3), dtype=np.float32)
                    
                    for b, band in enumerate(rgb_bands):
                        if band < patch.shape[0]:
                            band_data = patch[band]
                            min_val = np.percentile(band_data, 2)
                            max_val = np.percentile(band_data, 98)
                            rgb_patch[:, :, b] = np.clip((band_data - min_val) / (max_val - min_val), 0, 1)
                
                img_tensor = torch.tensor(patch, dtype=torch.float32)
                img_tensor = img_tensor.unsqueeze(0)
                
                with torch.inference_mode():
                    prediction = st.session_state.model(img_tensor)
                    prediction = torch.sigmoid(prediction).cpu()
                
                pred_np = prediction.squeeze().numpy()
                binary_mask = (pred_np > 0.5).astype(np.uint8) * 255
                
                output_filename = f"classified_region{patches_info['region_number']}_{i}_{j}.tif"
                output_path = os.path.join(classified_folder, output_filename)
                classified_paths.append(output_path)
                
                patch_meta.update({'count': 1, 'dtype': 'uint8'})
                
                with rasterio.open(output_path, 'w', **patch_meta) as dst:
                    dst.write(binary_mask.reshape(1, binary_mask.shape[0], binary_mask.shape[1]))
                
                if len(classified_results) < 6:
                    classified_results.append({
                        'path': output_path, 'i': i, 'j': j,
                        'mask': binary_mask, 'rgb_original': rgb_patch
                    })
                
                classify_progress.progress((idx + 1) / total_patches)
                
            except Exception as e:
                st.error(f"ÿÆÿ∑ÿß ÿØÿ± Ÿæÿ±ÿØÿßÿ≤ÿ¥ ÿ™⁄©Ÿá {patch_path}: {str(e)}")
        
        if year == st.session_state.before_year:
            st.session_state.classified_paths = classified_paths
            st.session_state.classified_shape = patches_shape
        else:
            st.session_state.classified_paths_2024 = classified_paths
            st.session_state.classified_shape_2024 = patches_shape
        
        if classified_results:
            st.subheader("ŸÜŸÖŸàŸÜŸá ŸÜÿ™ÿß€åÿ¨ ÿ∑ÿ®ŸÇŸá‚Äåÿ®ŸÜÿØ€å")
            
            num_samples = len(classified_results)
            fig, axes = plt.subplots(2, num_samples, figsize=(15, 8))
            
            for idx, result in enumerate(classified_results):
                axes[0, idx].imshow(result['rgb_original'])
                axes[0, idx].set_title(f"ÿßÿµŸÑ€å {result['i']}_{result['j']}")
                axes[0, idx].axis('off')
            
            for idx, result in enumerate(classified_results):
                axes[1, idx].imshow(result['mask'], cmap='gray')
                axes[1, idx].set_title(f"ÿ∑ÿ®ŸÇŸá‚Äåÿ®ŸÜÿØ€å ÿ¥ÿØŸá {result['i']}_{result['j']}")
                axes[1, idx].axis('off')
            
            plt.tight_layout()
            st.pyplot(fig)
        
        progress_placeholder.progress(75)
        status_placeholder.success(f"ŸÖÿ±ÿ≠ŸÑŸá 3 ÿßÿ≤ 4: {total_patches} ÿ™⁄©Ÿá ÿ®ÿß ŸÖŸàŸÅŸÇ€åÿ™ ÿ∑ÿ®ŸÇŸá‚Äåÿ®ŸÜÿØ€å ÿ¥ÿØ")
        
        # Step 4: Reconstruction
        status_placeholder.info("ŸÖÿ±ÿ≠ŸÑŸá 4 ÿßÿ≤ 4: ÿ®ÿßÿ≤ÿ≥ÿßÿ≤€å ÿ™ÿµŸà€åÿ± ⁄©ÿßŸÖŸÑ...")
        
        if year == st.session_state.before_year:
            patches_info = st.session_state.patches_info
            classified_paths = st.session_state.classified_paths
            patches_shape = st.session_state.classified_shape
            clipped_meta = st.session_state.clipped_meta
        else:
            patches_info = st.session_state.patches_info_2024
            classified_paths = st.session_state.classified_paths_2024
            patches_shape = st.session_state.classified_shape_2024
            clipped_meta = st.session_state.clipped_meta_2024
        
        patches = []
        patch_indices = []
        
        for path in classified_paths:
            filename = os.path.basename(path)
            parts = filename.split('_')
            i_j_part = parts[-2:]
            i = int(i_j_part[0])
            j = int(i_j_part[1].split('.')[0])
            
            with rasterio.open(path) as src:
                patch = src.read(1)
                patches.append(patch)
                patch_indices.append((i, j))
        
        i_vals = [idx[0] for idx in patch_indices]
        j_vals = [idx[1] for idx in patch_indices]
        max_i = max(i_vals) + 1
        max_j = max(j_vals) + 1
        
        patch_size = patches_info['patch_size']
        grid = np.zeros((max_i, max_j, patch_size, patch_size), dtype=np.uint8)
        
        for (i, j), patch in zip(patch_indices, patches):
            grid[i, j] = patch
        
        reconstructed_image = unpatchify(grid, (max_i * patch_size, max_j * patch_size))
        
        base_dir = os.path.dirname(image_path)
        output_filename = f"reconstructed_classification_{year}_region{region_number}.tif"
        output_path = os.path.join(base_dir, output_filename)
        
        out_meta = clipped_meta.copy()
        out_meta.update({
            'count': 1,
            'height': reconstructed_image.shape[0],
            'width': reconstructed_image.shape[1],
            'dtype': 'uint8'
        })
        
        with rasterio.open(output_path, 'w', **out_meta) as dst:
            dst.write(reconstructed_image, 1)
        
        if year == st.session_state.before_year:
            st.session_state.reconstructed_before_path = output_path
            st.session_state.reconstructed_before_image = reconstructed_image
        else:
            st.session_state.reconstructed_after_path = output_path
            st.session_state.reconstructed_after_image = reconstructed_image
        
        fig, ax = plt.subplots(figsize=(10, 10))
        ax.imshow(reconstructed_image, cmap='gray')
        ax.set_title(f"ÿ™ÿµŸà€åÿ± ÿ∑ÿ®ŸÇŸá‚Äåÿ®ŸÜÿØ€å ÿ®ÿßÿ≤ÿ≥ÿßÿ≤€å ÿ¥ÿØŸá ({year})")
        ax.axis('off')
        st.pyplot(fig)
        
        with open(output_path, "rb") as file:
            st.download_button(
                label=f"ÿØÿßŸÜŸÑŸàÿØ ÿ∑ÿ®ŸÇŸá‚Äåÿ®ŸÜÿØ€å ÿ®ÿßÿ≤ÿ≥ÿßÿ≤€å ÿ¥ÿØŸá ({year})",
                data=file,
                file_name=output_filename,
                mime="image/tiff"
            )
        
        progress_placeholder.progress(100)
        status_placeholder.success(f"ÿ™ŸÖÿßŸÖ ŸÖÿ±ÿßÿ≠ŸÑ Ÿæÿ±ÿØÿßÿ≤ÿ¥ ÿ®ÿ±ÿß€å {year} ÿ®ÿß ŸÖŸàŸÅŸÇ€åÿ™ ÿßŸÜÿ¨ÿßŸÖ ÿ¥ÿØ!")
        
        return True
        
    except Exception as e:
        status_placeholder.error(f"ÿÆÿ∑ÿß ÿØÿ± Ÿæÿ±ÿØÿßÿ≤ÿ¥: {str(e)}")
        import traceback
        st.error(traceback.format_exc())
        return False
                
